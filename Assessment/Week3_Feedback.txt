Starting weekly assessment for HongYe, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 1.57 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week1, Assessment, Week2, .git, Week3

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*~ 
*.tmp

# Created by https://www.gitignore.io/api/r,linux,python

### Linux ###
*~

# temporary files which can be created if a process still has a handle open of a deleted file
.fuse_hidden*

# KDE directory preferences
.directory

# Linux trash folder which might appear on any partition or disk
.Trash-*

# .nfs files are created when an open file is removed but is still being accessed
.nfs*

### Python ###
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

### Python Patch ###
.venv/

### Python.VirtualEnv Stack ###
# Virtualenv
# http://iamzed.com/2009/05/07/a-primer-on-virtualenv/
[Bb]in
[Ii]nclude
[Ll]ib
[Ll]ib64
[Ll]ocal
[Ss]cripts
pyvenv.cfg
pip-selfcheck.json

### R ###
# History files
.Rhistory
.Rapp.history

# Session Data files
.RData

# Example code in package build process
*-Ex.R

# Output files from R CMD build
/*.tar.gz

# Output files from R CMD check
/*.Rcheck/

# RStudio files
.Rproj.user/

# produced vignettes
vignettes/*.html
vignettes/*.pdf

# OAuth2 token, see https://github.com/hadley/httr/releases/tag/v0.3
.httr-oauth

# knitr and R markdown default cache directories
/*_cache/
/cache/

# Temporary files created by R markdown
*.utf8.md
*.knit.md

# Shiny token, see https://shiny.rstudio.com/articles/shinyapps.html
rsconnect/

### R.Bookdown Stack ###
# R package: bookdown caching files
/*_files/


# End of https://www.gitignore.io/api/r,linux,python


# Created by https://www.gitignore.io/api/latex

### LaTeX ###
## Core latex/pdflatex auxiliary files:
*.aux
*.lof
*.log
*.lot
*.fls
*.out
*.toc
*.fmt
*.fot
*.cb
*.cb2
.*.lb

## Intermediate documents:
*.dvi
*.xdv
*-converted-to.*
# these rules might exclude image files for figures etc.
# *.ps
# *.eps
# *.pdf

## Generated if empty string is given at "Please type another file name for output:"
.pdf

## Bibliography auxiliary files (bibtex/biblatex/biber):
*.bbl
*.bcf
*.blg
*-blx.aux
*-blx.bib
*.run.xml

## Build tool auxiliary files:
*.fdb_latexmk
*.synctex
*.synctex(busy)
*.synctex.gz
*.synctex.gz(busy)
*.pdfsync

## Build tool directories for auxiliary files
# latexrun
latex.out/

## Auxiliary and intermediate files from other packages:
# algorithms
*.alg
*.loa

# achemso
acs-*.bib

# amsthm
*.thm

# beamer
*.nav
*.pre
*.snm
*.vrb

# changes
*.soc

# comment
*.cut

# cprotect
*.cpt

# elsarticle (documentclass of Elsevier journals)
*.spl

# endnotes
*.ent

# fixme
*.lox

# feynmf/feynmp
*.mf
*.mp
*.t[1-9]
*.t[1-9][0-9]
*.tfm

#(r)(e)ledmac/(r)(e)ledpar
*.end
*.?end
*.[1-9]
*.[1-9][0-9]
*.[1-9][0-9][0-9]
*.[1-9]R
*.[1-9][0-9]R
*.[1-9][0-9][0-9]R
*.eledsec[1-9]
*.eledsec[1-9]R
*.eledsec[1-9][0-9]
*.eledsec[1-9][0-9]R
*.eledsec[1-9][0-9][0-9]
*.eledsec[1-9][0-9][0-9]R

# glossaries
*.acn
*.acr
*.glg
*.glo
*.gls
*.glsdefs

# gnuplottex
*-gnuplottex-*

# gregoriotex
*.gaux
*.gtex

# htlatex
*.4ct
*.4tc
*.idv
*.lg
*.trc
*.xref

# hyperref
*.brf

# knitr
*-concordance.tex
# TODO Comment the next line if you want to keep your tikz graphics files
*.tikz
*-tikzDictionary

# listings
*.lol

# makeidx
*.idx
*.ilg
*.ind
*.ist

# minitoc
*.maf
*.mlf
*.mlt
*.mtc[0-9]*
*.slf[0-9]*
*.slt[0-9]*
*.stc[0-9]*

# minted
_minted*
*.pyg

# morewrites
*.mw

# nomencl
*.nlg
*.nlo
*.nls

# pax
*.pax

# pdfpcnotes
*.pdfpc

# sagetex
*.sagetex.sage
*.sagetex.py
*.sagetex.scmd

# scrwfile
*.wrt

# sympy
*.sout
*.sympy
sympy-plots-for-*.tex/

# pdfcomment
*.upa
*.upb

# pythontex
*.pytxcode
pythontex-files-*/

# tcolorbox
*.listing

# thmtools
*.loe

# TikZ & PGF
*.dpth
*.md5
*.auxlock

# todonotes
*.tdo

# easy-todo
*.lod

# xcolor
*.xcp

# xmpincl
*.xmpi

# xindy
*.xdy

# xypic precompiled matrices
*.xyc

# endfloat
*.ttt
*.fff

# Latexian
TSWLatexianTemp*

## Editors:
# WinEdt
*.bak
*.sav

# Texpad
.texpadtmp

# LyX
*.lyx~

# Kile
*.backup

# KBibTeX
*~[0-9]*

# auto folder when using emacs and auctex
./auto/*
*.el

# expex forward references with \gathertags
*-tags.tex

# standalone packages
*.sta

### LaTeX Patch ###
# glossaries
*.glstex


# End of https://www.gitignore.io/api/latex
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
![Logo of the project](https://raw.githubusercontent.com/jehna/readme-best-practices/master/sample-logo.png)

# MY CMEE 2019-2020 COURSEWORK REPOSITORY
> A place to submit my CMEE coursework from week1 to week7.


## Getting started

Hello~ Wellcome to my repository!
At your terminal, please run:
* git clone https://github.com/Grace1016/CMEECourseWork.git


## Introduction

Here's a brief introduction about my repository. There are seven directories named Week1-7 which  contain the codes, datas, sandbox and results from my weekly work. The .gitignore file helps to avoid submitting rubbish files. 


## Content
* Week1(linux and Unix)
* Week2(PythonI)
* Week3(R and Data Management)
* to be continue...



**********************************************************************

======================================================================
Looking for the weekly directories...

Found 3 weekly directories: Week1, Week2, Week3

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: code, data

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
![Logo of the project](https://raw.githubusercontent.com/jehna/readme-best-practices/master/sample-logo.png)

# Week3 Coursework
> This directory contains folders of code, data, results.

## Code
* apply1.R: using applying the same function to rows/colums of a matrix using apply.
* apply2.R: using apply to define your own functions.
* basic_io.R: a simple script to illustrate R input-output.
* boilerplate.R: a boilerplate R script.
* break.R: an example of using "break" to break out a loop.
* browse.R: an example usage of browser().
* control_flow.R: some examples of code exemplifying control flow tools in R.
* Control.R: some code exemplifying control flow constructs in R.
* cp_cpt_speed.sh: compare computational speed in four script.
* DataWrang.R: wrangling a big dataset by different ways.
* DataWrangTidy.R: wrangling a big dataset by different ways.
* get_TreeHeight.py: this function calculates heights of trees given distance of each tree
 from its base and angle to its top, using  the trigonometric formula.
* get_TreeHeight.R: This function calculates heights of trees given distance of each tree 
 from its base and angle to its top, using  the trigonometric formula.
* Girko.R: plotting two dataframes.
* mapping: create a world map and superimposes the location points.
* MyBars.R: annotating plots and creating a bar. 
* next.R: an example of using next.
* PlotLin.R: plotting lineranges.
* PP_Lattice.R: draws three lattice pictures and gives some analysis.
* PP_Regress_loc.R: draws a picture as requirement and gives some analysis.
* PP_Regress.R: draws a picture as requirement and gives some analysis.
* preallocate.R: two examples to show the advantage of pre-allocation.
* Ricker.R: run a simulation of the Ricker model.
* run_get_TreeHeight.sh: a bash script to run the get_TreeHeight.R and get_TreeHeight.py.
* sample.R: run a simulation that involves sampling from a population.
* TAutoCorr.R: finds the correlation coefficient and P value then gives an interpretation in pdf.
* TAutoCorr.tex: finds the correlation coefficient and P value then gives an interpretation in pdf.
* TreeHeight.R: This function calculates heights of trees given distance of each tree from its base and angle to its top, using  the trigonometric formula.
* try.R: run a simulation that involves sampling from a population with try.
* Vectorize1.py: using vectorize to simplify the code in different version.
* Vectorize1.R: using vectorize to simplify the code in different version.
* Vectorize2.py: using vectorize to simplify the code in different version.
* Vectorize2.R: using vectorize to simplify the code in different version.
* Vectorizel.R: an example of vectorization.

## Data
* EcolArchives-E089-51-D1.csv
* filename 
* GPDDFiltered.RData
* KeyWestAnnualMeanTemperature.RData
* PoundHillData.csv
* PoundHillMetaData.csv
* Results.txt
* tree_treeheights.csv
* tree.csv

## Results
* A folder where some final results will be outputed in.
* Has been cleaned up!**********************************************************************

Results directory missing!

Creating Results directory...

Found 34 code files: browse.R, PP_Regress.R, Vectorize2.py, apply1.R, sample.R, Vectorizel.R, control_flow.R, run_get_TreeHeight.sh, get_TreeHeight.py, Control.R, boilerplate.R, TreeHeight.R, PP_Lattice.R, PlotLin.R, next.R, Ricker.R, Girko.R, cp_cpt_speed.sh, Vectorize1.R, break.R, basic_io.R, Vectorize1.py, try.R, apply2.R, get_TreeHeight.R, TAutoCorr.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, PP_Regress_loc.R, mapping.R, DataWrang.R, TAutoCorr.tex, MyBars.R

======================================================================
Testing script/code files...

======================================================================
Inspecting script file browse.R...

File contents are:
**********************************************************************
### an example usage of browser() ###

Exponential <- function(N0 = 1, r = 1, generations = 10){
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations){
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")**********************************************************************

Testing browse.R...

Output (only first 500 characters): 

**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.13247s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:
**********************************************************************
#CREATE A GRAPHICS AS EXAMPLE FIGURE AND WRITE REGRESSION RESULTS
rm(list = ls())
# extract data
MyDF <-read.csv("../data/EcolArchives-E089-51-D1.csv")

library(ggplot2)
library(dplyr)

# create the figure
p <- ggplot(MyDF,aes(x=Prey.mass,y=Predator.mass,colour=Predator.lifestage))+geom_point(shape=3)
p <- p+facet_grid(Type.of.feeding.interaction~.)+geom_smooth(method = lm,fullrange=TRUE)
p <- p+scale_x_continuous(trans = "log10","Prey Mass in grams")+scale_y_continuous(trans = "log10","Predator Mass in grams")
p <- p+theme_bw()+theme(legend.position = "bottom")+coord_fixed(ratio = 0.3)+guides(color=guide_legend(nrow = 1))

# saving the graphic
pdf("../result/PP_Regress.pdf")
print(p)
dev.off()

# define a function to calculate slope,intercept,Rsquare,F-statistic value and p-value
fc <- function(x,y) {
  a <- lm(log(y)~log(x))
  intercept = summary(a)$coefficients[1]
  slope = summary(a)$coefficients[2]
  Rsquare = summary(a)$r.squared[1]
  f_statistic = summary(a)$fstatistic[1]
  p_value = summary(a)$coefficients[8]
  DF <- c(intercept,slope,Rsquare,f_statistic,p_value)
  return(DF)
}

# create a table
Results <- MyDF %>% group_by(Type.of.feeding.interaction,Predator.lifestage) %>%
  summarise(regression_intercept = fc(Prey.mass,Predator.mass)[1],
            regression_slope = fc(Prey.mass,Predator.mass)[2],
            Rsquare = fc(Prey.mass,Predator.mass)[3],
            f_value = fc(Prey.mass,Predator.mass)[4],
            p_vlaue = fc(Prey.mass,Predator.mass)[5])

write.csv(Results,"../result/PP_Regress.csv",row.names = FALSE)
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):

Attaching package: â€˜dplyrâ€™

The following objects are masked from â€˜package:statsâ€™:

    filter, lag

The following objects are masked from â€˜package:baseâ€™:

    intersect, setdiff, setequal, union

Error in pdf("../result/PP_Regress.pdf") : 
  cannot open file '../result/PP_Regress.pdf'
Execution halted

======================================================================
Inspecting script file Vectorize2.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3

"""A python version of Vectorize1.R2"""

__author__ = 'Hongye Wang (hw2419@ic.ac.uk)'

import math
import numpy as np
import time

# loop
def stochrick(p0 = np.random.uniform(0.5,1.5,size=1000),r=1.2,K=1,sigma=0.2,numyears=100):
    N = np.ones((numyears,len(p0)))
    N[1,] = p0
    for pop in range(1,len(p0)):
        for yr in range(2,numyears):
            N[yr,pop] = N[yr-1,pop]*math.exp(r*(1-N[yr-1,pop]/K)+np.random.normal(0,sigma,1))
    return(N)

#vectorize
def stochrickvect(p0 = np.random.uniform(0.5,1.5,size=1000),r=1.2,K=1,sigma=0.2,numyears=100):
    N = np.ones((numyears,len(p0)))
    N[1,] = p0
    for yr in range(2,numyears):
        N[yr,] = N[yr-1,]*np.exp(r*(1-N[yr-1,]/K)+np.random.normal(0,sigma,1))
    return(N)

res2 = stochrickvect()
a = time.time()
res2 = stochrickvect()
b = time.time()
res2_time = b-a

print("Vectorized Stochastic Ricker takes:")
print(res2_time)
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************
Vectorized Stochastic Ricker takes:
0.0032320022583007812

**********************************************************************

Code ran without errors

Time consumed = 0.16941s

======================================================================
Inspecting script file apply1.R...

File contents are:
**********************************************************************
### the *apply family of functions ###
## using applying the same function to rows/colums of a matrix using apply"
## Build a random matrix
M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

# By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 

**********************************************************************
 [1]  0.37732147 -0.46575527  0.43041897  0.24076179  0.16731740  0.20840887
 [7]  0.08694904 -0.38335723 -0.24990916  0.04597207
 [1] 0.2386480 0.5006456 0.8132792 0.8388946 1.2288015 0.7949068 1.8064212
 [8] 0.8896462 1.0402880 0.7446012
 [1] -0.30588602  0.17426741  0.06946806 -0.02323192  0.14430744  0.06509479
 [7] -0.24840610  0.19447676  0.37656291  0.01147464

**********************************************************************

Code ran without errors

Time consumed = 0.08133s

======================================================================
Inspecting script file sample.R...

File contents are:
**********************************************************************
######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n){
  pop_sample <- sample(popn, n, replace = FALSE)
  return(mean(pop_sample))
}

## Calculate means using a for loop without preallocation:
loopy_sample1 <- function(popn, n, num){
  result1 <- vector() #Initialize empty vector of size 1 
  for(i in 1:num){
    result1 <- c(result1, myexperiment(popn, n))
  }
  return(result1)
}

## To run "num" iterations of the experiment using a for loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num){
  result2 <- vector(,num) #Preallocate expected size
  for(i in 1:num){
    result2[i] <- myexperiment(popn, n)
  }
  return(result2)
}

## To run "num" iterations of the experiment using a for loop on a list with preallocation:
loopy_sample3 <- function(popn, n, num){
  result3 <- vector("list", num) #Preallocate expected size
  for(i in 1:num){
    result3[[i]] <- myexperiment(popn, n)
  }
  return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num){
  result4 <- lapply(1:num, function(i) myexperiment(popn, n))
  return(result4)
}

## To run "num" iterations of the experiment using vectorization with lapply:
sapply_sample <- function(popn, n, num){
  result5 <- sapply(1:num, function(i) myexperiment(popn, n))
  return(result5)
}

popn <- rnorm(1000) # Generate the population
hist(popn)

n <- 20 # sample size for each experiment
num <- 1000 # Number of times to rerun the experiment

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample1(popn, n, num)))

print("The loopy, but with preallocation approach takes:" )
print(system.time(loopy_sample2(popn, n, num)))

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample3(popn, n, num)))

print("The vectorized sapply approach takes:" )
print(system.time(sapply_sample(popn, n, num)))

print("The vectorized lapply approach takes:" )
print(system.time(lapply_sample(popn, n, num)))**********************************************************************

Testing sample.R...

Output (only first 500 characters): 

**********************************************************************
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.040   0.000   0.037 
[1] "The loopy, but with preallocation approach takes:"
   user  system elapsed 
  0.020   0.000   0.018 
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.016   0.000   0.016 
[1] "The vectorized sapply approach takes:"
   user  system elapsed 
  0.016   0.000   0.014 
[1] "The vectorized lapply approach takes:"
   user  system elapsed 
  0.012   0.000   0.013 

**********************************************************************

Code ran without errors

Time consumed = 0.30787s

======================================================================
Inspecting script file Vectorizel.R...

File contents are:
**********************************************************************
### an example of vectorization ###

M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M){
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){
    for (j in 1:Dimensions[2]){
      Tot <- Tot + M[i,j]
    }
  }
  return (Tot)
}

print("Using loops, the time taken is:")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is:")
print(system.time(sum(M)))**********************************************************************

Testing Vectorizel.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.096   0.000   0.098 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.000   0.000   0.001 

**********************************************************************

Code ran without errors

Time consumed = 0.27773s

======================================================================
Inspecting script file control_flow.R...

File contents are:
**********************************************************************
###some examples of code exemplifying control flow tools in R###

## If statement
a <- TRUE
if (a == TRUE){
  print ("a is TRUE")
} else {
  print ("a is FALSE")
}

## If statement on a single line
z <- runif(1) ## uniformly distributed random number
if (z <= 0.5) {print ("Less than a half")}

## For loop using a sequence
for (i in 1:10){
  j <- i * i
  print(paste(i, " squared is", j ))
}

## For loop over vector of strings
for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')){
  print(paste('The species is', species))
}

## for loop using a vector
v1 <- c("a","bc","def")
for (i in v1){
  print(i)
}

## While loop
i <- 0
while (i<10){
  i <- i+1
  print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 

**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.11667s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:
**********************************************************************
# !/bin/bash
# Author: Hongye Wang (hw2419@ic.ac.uk)
# Script: run_get_TreeHeight.sh
# Desc: text get_TreeHeight.R, get_TreeHeight.py in unix
# Arguments: none
# Date: Oct 2019

# text get_TreeHeight.R
Rscript get_TreeHeight.R ../data/trees.csv

# text get_TreeHeight.py
ipython3 get_TreeHeight.py ../data/trees.csv**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 

**********************************************************************
[1] "/usr/lib/R/bin/exec/R"   "--slave"                
[3] "--no-restore"            "--file=get_TreeHeight.R"
[5] "--args"                  "../data/trees.csv"      
]0;IPython: Week3/code[1;31m---------------------------------------------------------------------------[0m
[1;31mFileNotFoundError[0m                         Traceback (most recent call last)
[1;32m~/Documents/Teaching/IC_CMEE/2019-20/Coursework/StudentRepos/HongYeWang_HW2419/Week3/code/get_TreeHeight.py[0m in [0;36m<modul
**********************************************************************

Encountered error (or warning):
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
Calls: write.csv -> eval.parent -> eval -> eval -> write.table -> file
In addition: Warning message:
In file(file, ifelse(append, "a", "w")) :
  cannot open file '../result/ trees _treeheight.csv': No such file or directory
Execution halted

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
"""This function calculates heights of trees given distance of each tree
 from its base and angle to its top, using  the trigonometric formula"""

__author__ = 'Hongye Wang (hw2419@ic.ac.uk)'

# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"
import sys
import csv
import os
import math

def TreeHeight(degrees,distance):
  radians = degrees * math.pi / 180
  height = distance * math.tan(radians)
  return (height)

# import data and takes the file name from command line 
mydata = []
with open(sys.argv[1],"r") as f:
    for line in csv.reader(f):
        mydata.append(line)
f.close()

#set arguments and calculate the height of trees
mydata[0].append("Tree.Height.m")
for i in range(1,len(mydata)):
    mydata[i].append(TreeHeight(float(mydata[i][2]),float(mydata[i][1]))) 

#Result <- data.frame(mydata,Tree.Height.m) # combine treeheight with other datas of trees
#output <- head(Result,2) # cat first 2 datas in results

# output as request
with open("../result/"+os.path.splitext(os.path.basename(sys.argv[1]))[0]+"_treeheights.csv","w") as g:
    for line in mydata:
        csv.writer(g).writerow(line)
g.close()
**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Traceback (most recent call last):
  File "get_TreeHeight.py", line 27, in <module>
    with open(sys.argv[1],"r") as f:
IndexError: list index out of range

======================================================================
Inspecting script file Control.R...

File contents are:
**********************************************************************
### Some code exemplifying control flow constructs in R ###

## If statement
a <- TRUE
if (a == TRUE){
  print ("a is TRUE")
} else {
  print ("a is FALSE")
}

## On a single line
z <- runif(1) ##random number
if (z <= 0.5) {
  print ("Less than a quarter")
}

## For loop using a sequence
for (i in 1:100){
  j <- i * i
  print(paste(i, " squared is", j ))
}

## For loop over vector of strings
for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii'))
{
  print(paste('The species is', species))
}

## for loop using a vector
v1 <- c("a","bc","def")
for (i in v1){
  print(i)
}

## While loop
i <- 0
while (i<100){
  i <- i+1
  print(i^2)
}

**********************************************************************

Testing Control.R...

Output (only first 500 characters): 

**********************************************************************
[1] "a is TRUE"
[1] "Less than a quarter"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "11  squared is 121"
[1] "12  squared is 144"
[1] "13  squared is 169"
[1] "14  squared is 196"
[1] "15  squared is 225"
[1] "16  squared is 256"
[1] "17  squared is 289"
[1] "18  squared is 324"
[1] "19  squared is 361"
[1] "
**********************************************************************

Code ran without errors

Time consumed = 0.09581s

======================================================================
Inspecting script file boilerplate.R...

File contents are:
**********************************************************************
### A boilerplate R script ###

MyFunction <- function(Arg1, Arg2){
  
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
  
  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.09119s

======================================================================
Inspecting script file TreeHeight.R...

File contents are:
**********************************************************************
# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"
Mydata <- read.csv("../data/trees.csv", header = TRUE)


TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  #print(paste("Tree height is:", height))
  
  return (height)
}

Tree.Height.m <- TreeHeight(Mydata[,3], Mydata[,2])
Result <- cbind(Mydata, Tree.Height.m)
write.csv(Result, "../result/TreeHts.csv", row.names = FALSE)
**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
Calls: write.csv -> eval.parent -> eval -> eval -> write.table -> file
In addition: Warning message:
In file(file, ifelse(append, "a", "w")) :
  cannot open file '../result/TreeHts.csv': No such file or directory
Execution halted

======================================================================
Inspecting script file PP_Lattice.R...

File contents are:
**********************************************************************
# create three lattice plots and calculate the mean and median of each data
rm(list = ls())
# extract data and check the size and content of it
MyDF <-read.csv("../data/EcolArchives-E089-51-D1.csv")
str(MyDF)
dim(MyDF)

require(lattice)
# create and save lattice plots
pdf("../result/Pred_Lattice.pdf",11.7,8.3)
densityplot(~log(Predator.mass) | Type.of.feeding.interaction, data = MyDF)
dev.off()

pdf("../result/Prey_Lattice.pdf",11.7,8.3)
densityplot(~log(Prey.mass) | Type.of.feeding.interaction,data = MyDF)
dev.off()

pdf("../result/SizeRatio_Lattice.pdf",11.7,8.3)
densityplot(~log(Prey.mass/Predator.mass) | Type.of.feeding.interaction, data = MyDF)
dev.off()

# calculate and output the mean and median 
require(dplyr)
table <- MyDF %>% select(Predator.mass,Prey.mass,Type.of.feeding.interaction) %>%
  mutate(Ratio=Prey.mass/Predator.mass) %>%
  group_by(Type.of.feeding.interaction) %>%
  summarise(mean_Pred.mass=mean(log(Predator.mass)),mean_Prey.mass=mean(log(Predator.mass)),mean_Ratio=mean(log(Ratio)),
            median_Pred.mass=median(log(Predator.mass)),medain_Prey.mass=median(log(Prey.mass)),median_Ratio=median(log(Ratio))) %>%
  ungroup()

# output as .csv file
write.table(table,"../result/PP_Results.csv",row.names = FALSE)
**********************************************************************

Testing PP_Lattice.R...

Output (only first 500 characters): 

**********************************************************************
'data.frame':	34931 obs. of  15 variables:
 $ Record.number              : int  1 2 3 4 5 6 7 8 9 10 ...
 $ In.refID                   : Factor w/ 1218 levels "07/08/12","111-10",..: 1000 1004 1007 1012 1013 1014 1015 1017 1018 1018 ...
 $ IndividualID               : Factor w/ 17625 levels "1","10","100",..: 1 8781 9875 10984 12076 13187 14298 15407 16518 16518 ...
 $ Predator                   : Factor w/ 93 levels "Acanthocepola sp.",..: 72 72 72 72 72 72 72 72 72 72 ...
 $ Predator.common.nam
**********************************************************************

Encountered error (or warning):
Loading required package: lattice
Error in pdf("../result/Pred_Lattice.pdf", 11.7, 8.3) : 
  cannot open file '../result/Pred_Lattice.pdf'
Execution halted

======================================================================
Inspecting script file PlotLin.R...

File contents are:
**********************************************************************
rm(list = ls())
require(ggplot2)
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                   parse = TRUE, size = 6, 
                   colour = "blue")

pdf("../result/MyLinReg.pdf")
p
dev.off()

**********************************************************************

Testing PlotLin.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2
Error in pdf("../result/MyLinReg.pdf") : 
  cannot open file '../result/MyLinReg.pdf'
Execution halted

======================================================================
Inspecting script file next.R...

File contents are:
**********************************************************************
### an example of using next"

for (i in 1:10) {
  if ((i %% 2) == 0) 
    next # pass to next iteration of loop 
  print(i)
}

**********************************************************************

Testing next.R...

Output (only first 500 characters): 

**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.10832s

======================================================================
Inspecting script file Ricker.R...

File contents are:
**********************************************************************
Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

plot(Ricker(generations=10), type="l")**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.15511s

======================================================================
Inspecting script file Girko.R...

File contents are:
**********************************************************************

rm(list = ls())
require(ggplot2)
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
pdf("../result/Girko.pdf",11.7,8.3)
print(p)
dev.off()**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2
Error in pdf("../result/Girko.pdf", 11.7, 8.3) : 
  cannot open file '../result/Girko.pdf'
Execution halted

======================================================================
Inspecting script file cp_cpt_speed.sh...

File contents are:
**********************************************************************
#!/bin/bash
# Script: cp_cpt_speed.sh
# Author:Hongye Wang (hw2419.ic.ac.uk)
# Desc: Compare computational speed in four script
# Date: Dec 2019

echo -e "computational speed in loop and vectorize namely when running Vectorize1.R \n"
Rscript Vectorize1.R 

echo -e  "\n computational speed in loop and vectorize when running Vectorize1.py \n"
python3 Vectorize1.py

echo -e "\n computational speed in vectorize when running Vectorize2.py \n"
Rscript Vectorize2.R

echo -e "\n computational speed in vectorize when running Vectorize2.py \n"
python3 Vectorize2.py

**********************************************************************

Testing cp_cpt_speed.sh...

Output (only first 500 characters): 

**********************************************************************
computational speed in loop and vectorize namely when running Vectorize1.R 

   user  system elapsed 
  0.100   0.000   0.098 
   user  system elapsed 
  0.000   0.000   0.002 

 computational speed in loop and vectorize when running Vectorize1.py 

SUM ALL ELEMENTS In Loop takes:
0.231642484664917
Sum all elements by vectorize takes:
0.0021157264709472656

 computational speed in vectorize when running Vectorize2.py 

[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.040   0
**********************************************************************

Code ran without errors

Time consumed = 1.00614s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:
**********************************************************************
M <- matrix(runif(1000000),1000,1000)

SumALLElements <- function(M){
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){
    for (j in 1:Dimensions[2]){
      Tot <- Tot + M[i,j]
    }
  }
  return(Tot)  
  }
  
  ## This on my computer takes about 1 sec
  print(system.time(SumALLElements(M)))
  ## While this takes about 0.01 sec
  print(system.time(sum(M)))
  **********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 

**********************************************************************
   user  system elapsed 
  0.100   0.000   0.101 
   user  system elapsed 
  0.000   0.000   0.002 

**********************************************************************

Code ran without errors

Time consumed = 0.27938s

======================================================================
Inspecting script file break.R...

File contents are:
**********************************************************************
### an example of using "break" to break out a loop ###

i <- 0 #Initialize i
while(i < Inf) {
  if (i == 10) {
    break 
  } # Break out of the while loop! 
  else { 
    cat("i equals " , i , " \n")
    i <- i + 1 # Update i
  }
}**********************************************************************

Testing break.R...

Output (only first 500 characters): 

**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  

**********************************************************************

Code ran without errors

Time consumed = 0.10705s

======================================================================
Inspecting script file basic_io.R...

File contents are:
**********************************************************************
# A simple script to illustrate R input-output.  
# Run line by line and check inputs outputs to understand what is happening  

MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../results/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../results/MyData.csv", col.names=FALSE) # ignore column names**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
Calls: write.csv -> eval.parent -> eval -> eval -> write.table -> file
In addition: Warning message:
In file(file, ifelse(append, "a", "w")) :
  cannot open file '../results/MyData.csv': No such file or directory
Execution halted

======================================================================
Inspecting script file Vectorize1.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3

"""A python version of Vectorize1.R"""

__author__ = 'Hongye Wang (hw2419@ic.ac.uk)'

# import modules
import numpy as np
import time

M = np.random.uniform(low=0,high=1,size=[1000,1000])
def SumALLElements(M):
    ToT = 0
    for i in range(0,M.shape[0]):
        for j in range(0,M.shape[1]):
            ToT = ToT+M[i,j]
    return ToT

a = time.time()
SumALLElements(M)
b = time.time()
time1 = b-a
print("SUM ALL ELEMENTS In Loop takes:")
print(time1)

c = time.time()
np.sum(M)
d = time.time()
time2 = d-c
print("Sum all elements by vectorize takes:")
print(time2)
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************
SUM ALL ELEMENTS In Loop takes:
0.18859338760375977
Sum all elements by vectorize takes:
0.0006098747253417969

**********************************************************************

Code ran without errors

Time consumed = 0.34872s

======================================================================
Inspecting script file try.R...

File contents are:
**********************************************************************
### run a simulation that involves sampling from a population with try ###

x <- rnorm(50) #Generate your population
doit <- function(x){
  x <- sample(x, replace = TRUE)
  if(length(unique(x)) > 30) {#only take mean if sample was sufficient
    print(paste("Mean of this sample was:", as.character(mean(x))))
  } 
  else {
    stop("Couldn't calculate mean: too few unique points!")
  }
}

## Try using "try" with vectorization:
result <- lapply(1:100, function(i) try(doit(x), FALSE))

## Or using a for loop:
result <- vector("list", 100) #Preallocate/Initialize
for(i in 1:100) {
  result[[i]] <- try(doit(x), FALSE)
}
**********************************************************************

Testing try.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Mean of this sample was: -0.350465091608024"
[1] "Mean of this sample was: -0.357733707248728"
[1] "Mean of this sample was: -0.41404242242805"
[1] "Mean of this sample was: -0.294758272771083"
[1] "Mean of this sample was: -0.124127708132944"
[1] "Mean of this sample was: -0.322102517065717"
[1] "Mean of this sample was: -0.169686420557398"
[1] "Mean of this sample was: -0.306974544626288"
[1] "Mean of this sample was: -0.12842225677136"
[1] "Mean of this sample was: -0.283141245973257"
[1]
**********************************************************************

Encountered error (or warning):
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!

======================================================================
Inspecting script file apply2.R...

File contents are:
**********************************************************************
### using apply to define your own functions ###

SomeOperation <- function(v){ 
  if (sum(v) > 0){
    return (v * 100)
  }
  return (v)
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 

**********************************************************************
             [,1]         [,2]        [,3]       [,4]        [,5]      [,6]
 [1,] -1.21151623    0.6831054  0.65799384  35.675306 -1.79837588 -40.17112
 [2,] -0.68318360  108.6444911  0.53604395 233.861006  0.28578712  92.46930
 [3,] -0.29777406 -123.6586470 -1.58683362  -1.434913 -1.61584652 -31.61319
 [4,]  0.78934030  -11.5597953 -0.09732723 -55.627825 -0.04162513 -73.26319
 [5,]  0.20797800   57.7385567  0.73651571  -3.239351 -1.47545455 133.72332
 [6,] -1.27019336    8.7628642  0.70160921 -4
**********************************************************************

Code ran without errors

Time consumed = 0.09032s

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:
**********************************************************************
# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  
  return (height)
}

# import data and takes the file name from command line 
args <- commandArgs()
print(args)
mydata <- read.csv(args[6],header = TRUE)

#set arguments and calculate the height of trees
degrees <- mydata[,3]
distance <- mydata[,2]
Tree.Height.m <-TreeHeight(degrees,distance)

Result <- data.frame(mydata,Tree.Height.m) # combine treeheight with other datas of trees
output <- head(Result,2) # cat first 2 datas in result

# output as request
FileName <- tools::file_path_sans_ext(basename(args[6]))
write.csv(output, paste("../result/",FileName,"_treeheight.csv"), row.names = FALSE)



**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
[1] "/usr/lib/R/bin/exec/R"   "--slave"                
[3] "--no-restore"            "--file=get_TreeHeight.R"

**********************************************************************

Encountered error (or warning):
Error in file(file, "rt") : cannot open the connection
Calls: read.csv -> read.table -> file
In addition: Warning message:
In file(file, "rt") : cannot open file 'NA': No such file or directory
Execution halted

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:
**********************************************************************
# load and examine and plot the data
load("../data/KeyWestAnnualMeanTemperature.RData")
plot(ats)

# calculate correlation between successive years
Temperatur_cor <- cor(ats$Temp[1:99],ats$Temp[2:100])

# calculate the random correlation
random_cor <- rep(NA,10000)
for (i in 1:10000) {
  random_tem <- sample(ats$Temp)
  random_cor[i] <- cor(random_tem[1:99],random_tem[2:100])
}

# calculate the p-value
p_value <- length(random_cor[random_cor>Temperatur_cor])/length(random_cor)
hist(random_cor,probability = TRUE,xlab = "random correlation coefficients",ylab = "density")
print(p_value)
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 

**********************************************************************
[1] 2e-04

**********************************************************************

Code ran without errors

Time consumed = 0.59564s

======================================================================
Inspecting script file Vectorize2.R...

File contents are:
**********************************************************************
# Runs the stochastic (with gaussian fluctuations) Ricker Eqn .

rm(list=ls())

stochrick<-function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  
  for (pop in 1:length(p0)) #loop through the populations
  {
    for (yr in 2:numyears) #for each pop, loop through the years
    {
      N[yr,pop]<-N[yr-1,pop]*exp(r*(1-N[yr-1,pop]/K)+rnorm(1,0,sigma))
    }
  }
  return(N)
}

stochrickvect <- function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  for (yr in 2:numyears)
  {
    N[yr,] = N[yr-1,]*exp(r*(1-N[yr-1,]/K)+rnorm(1,0,sigma))
  }
  
  return(N)
  
}
print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))





**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.036   0.000   0.037 

**********************************************************************

Code ran without errors

Time consumed = 0.10968s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:
**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

require(dplyr)
require(tidyr)
############# Inspect the dataset ###############
dplyr::tbl_df(MyData) 
dim(MyData)
dplyr::glimpse(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############

MyWrangledData <- TempData %>%
  gather(key = Species,
         value = Count,
         -1,-2,-3,-4) %>%
  mutate(Cultivation = as.factor(Cultivation),
         Block = as.factor(Block),
         Plot = as.factor(Plot),
         Quadrat = as.factor(Quadrat),
         Species = as.factor(Species),
         Count = as.numeric(Count))

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Start exploring the data (extend the script below)!  ###############

MyWrangledData %>% filter(Cultivation %in% c("october","march"))%>%
  select(Count)%>%
  head(5)
**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 

**********************************************************************
# A tibble: 45 x 60
   V1    V2    V3    V4    V5    V6    V7    V8    V9    V10   V11   V12   V13  
   <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>
 1 Cultâ€¦ octoâ€¦ octoâ€¦ octoâ€¦ octoâ€¦ octoâ€¦ may   may   may   may   may   march march
 2 Block a     a     a     a     a     a     a     a     a     a     a     a    
 3 Plot  1     1     1     1     1     2     2     2     2     2     3     3    
 4 Quadâ€¦ Q1    Q2    Q3    Q4    Q5    Q1    Q2    Q3    Q4    Q5    Q1    Q
**********************************************************************

Encountered error (or warning):
Loading required package: dplyr

Attaching package: â€˜dplyrâ€™

The following objects are masked from â€˜package:statsâ€™:

    filter, lag

The following objects are masked from â€˜package:baseâ€™:

    intersect, setdiff, setequal, union

Loading required package: tidyr

======================================================================
Inspecting script file preallocate.R...

File contents are:
**********************************************************************
### two examples to show the advantage of pre-allocation ###
### without pre-allocation ###
time <- as.numeric(proc.time())[1]
a <- NA
for (i in 1:10) {
  a <- c(a, i)
  print(a)
  print(object.size(a))
}
time2 <- as.numeric(proc.time())[1]
using_time <- time2-time
print(paste("Without Pre-allocation, it takes:",using_time))

### Using pre-allocation ###
a <- rep(NA, 10)
pre_allocation <- function(a){
for (i in 1:10) {
  a[i] <- i
  print(a)
  print(object.size(a))
 }
}
print("Using pre-allocation,it takes")
print(system.time(pre_allocation(a)))
**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 

**********************************************************************
[1] NA  1
48 bytes
[1] NA  1  2
56 bytes
[1] NA  1  2  3
56 bytes
[1] NA  1  2  3  4
72 bytes
[1] NA  1  2  3  4  5
72 bytes
[1] NA  1  2  3  4  5  6
72 bytes
[1] NA  1  2  3  4  5  6  7
72 bytes
[1] NA  1  2  3  4  5  6  7  8
88 bytes
 [1] NA  1  2  3  4  5  6  7  8  9
88 bytes
 [1] NA  1  2  3  4  5  6  7  8  9 10
88 bytes
[1] "Without Pre-allocation, it takes: 0.02"
[1] "Using pre-allocation,it takes"
 [1]  1 NA NA NA NA NA NA NA NA NA
88 bytes
 [1]  1  2 NA NA NA NA NA NA NA NA
88 bytes
 [1] 
**********************************************************************

Code ran without errors

Time consumed = 0.11568s

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:
**********************************************************************
rm(list = ls())
# extract data
MyDF <-read.csv("../data/EcolArchives-E089-51-D1.csv")

# define a function to calculate slope,intercept,Rsquare,F-statistic value and p-value
fc <- function(x,y) {
  a <- lm(log(y)~log(x))
  intercept = summary(a)$coefficients[1]
  slope = summary(a)$coefficients[2]
  Rsquare = summary(a)$r.squared[1]
  f_statistic = summary(a)$fstatistic[1]
  p_value = summary(a)$coefficients[8]
  DF <- c(intercept,slope,Rsquare,f_statistic,p_value)
  return(DF)
}

# create a table
Results <- MyDF %>% group_by(Type.of.feeding.interaction,Predator.lifestage,Location) %>%
  summarise(regression_intercept = fc(Prey.mass,Predator.mass)[1],
            regression_slope = fc(Prey.mass,Predator.mass)[2],
            Rsquare = fc(Prey.mass,Predator.mass)[3],
            f_value = fc(Prey.mass,Predator.mass)[4],
            p_vlaue = fc(Prey.mass,Predator.mass)[5])

write.csv(Results,"../result/PP_Regress_Loc.csv",row.names = FALSE)**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Error in MyDF %>% group_by(Type.of.feeding.interaction, Predator.lifestage,  : 
  could not find function "%>%"
Execution halted

======================================================================
Inspecting script file mapping.R...

File contents are:
**********************************************************************
### create a world map and superimposes the location points ###
require(maps)
require(ggplot2)
load("../data/GPDDFiltered.RData")
attach(gpdd)
# map the world with points
mp <- NULL
mapWorld <- borders("world",colour = "gray50",fill = "gray50")
mp <- ggplot() + mapWorld

# layer the species on the world
mp <- mp + geom_point(aes(x=gpdd$long,y=gpdd$lat),colour="yellow",size=3)
mp


# most of the species are located at latitude 50 degrees north of the world.
# I think the biase of this database is the distribution of the species is limited.
# For instance, When analysing the migration of global species, this data may not be generalizable **********************************************************************

Testing mapping.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Loading required package: maps
Loading required package: ggplot2

======================================================================
Inspecting script file DataWrang.R...

File contents are:
**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), 
variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.numeric(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Start exploring the data (extend the script below)!  ###############
**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 

**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Code ran without errors

Time consumed = 10.00532s

======================================================================
Inspecting script file TAutoCorr.tex...

File contents are:
**********************************************************************
\documentclass[12pt]{article}
\title{Report of "Autocorrelation in weather"}
\author{Ran Tao}
\date{October 2018}
\begin{document}
  \maketitle

  \begin{abstract}
    This paper report the results of the "Autocorrelation in weather" project and give interpretation
  \end{abstract}

  \section{Introduction}
    Autocorrelation in weather: The goal is to answer the question: Are temperatures of one year significantly correlated with the next year (successive years), across years in a given location? For this, you need to calculate the correlation between nâˆ’1 pairs of years, where n is the total number of years. However, you can't use the standard p-value calculated for a correlation coefficient, because measurements of climatic variables in successive time-points in a time series (successive seconds, minutes, hours, months, years, etc.) are not independent. 

  \section{Methods}
    1.Compute the appropriate correlation coefficient between successive years
    2.Repeat this calculation 10000 times by -- randomly permuting the time series, and then recalculating the correlation coefficient for each randomly permuted year sequence
    3.Then calculate what fraction of the correlation coefficients from the previous step were greater than that from step 1 (this is your approximate p-value)

  \section{results}
    Pvalue is not a constant value because the samples are random. Pvalue = n*e-04(n is not constant but less than 10)

  \section{interpretation}
    P value is so small that is less than 0.001, so the possibility of the correlation coefficient between successive year larger than between random year is higher than 99.9 of one hundred percent. Therefore the temperatures of one year significantly correlated with the next year (successive years) 
  
\end{document}
\grid**********************************************************************

Testing TAutoCorr.tex...

======================================================================
Inspecting script file MyBars.R...

File contents are:
**********************************************************************

rm(list = ls())
a <- read.table("../data/Results.txt",header = TRUE)
head(a)

a$ymin <- rep(0,dim(a)[1])

#Print the first linerange
library(ggplot2)
p <- ggplot(a)
p <- p+geom_linerange(data = a,aes(x=x,ymin=ymin,ymax=y1,size=0.5),
                      colour="#E69F00",
                      alpha=1/2,
                      show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
  x = x,
  ymin = ymin,
  ymax = y2,
  size = (0.5)
),
colour = "#56B4E9",
alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
  x = x,
  ymin = ymin,
  ymax = y3,
  size = (0.5)
),
colour = "#D55E00",
alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
  scale_y_continuous("My y axis") + 
  theme_bw() + 
  theme(legend.position = "none") 

pdf("../result/MyBars.pdf")
print(p)
dev.off()
p
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 

**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>

**********************************************************************

Encountered error (or warning):
Error in pdf("../result/MyBars.pdf") : 
  cannot open file '../result/MyBars.pdf'
Execution halted

======================================================================
======================================================================
Finished running scripts

Ran into 14 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!